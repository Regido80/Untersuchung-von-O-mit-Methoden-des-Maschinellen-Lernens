# Untersuchung-von-O-mit-Methoden-des-Maschinellen-Lernens

In den letzten Jahren gewannen die Begriffe K√ºnstliche Intelligenz, Neuronale Netze und Deep Learning immer weiter an medialer Aufmerksamkeit/Bedeutung.
Meldungen √ºber neue M√∂glichkeiten etwa in der Gesichtserkennung,dem autonomen Fahren oder der Simulation menschlichen Verhaltens erzeugen grosses Interesse und ein weites gesellschaftliches Echo.
Dennoch sind KI Werkzeuge nicht allm√§chtig und kognitive F√§higkeiten wie selbstst√§ndiges Denken sind noch nicht maschinell nachahmbar.
Damit bleiben auch wesentliche Teile der h√∂heren Mathematik dem Zugang und der Bearbeitung durch Neuronale Netze verschlossen.

Im Folgenden soll eine M√∂glichkeit vorgestellt werden wie, auf KI basierende Klassifikationsverfahren und Vergleichsmethoden, auf gewisse mathematische Objekte, den sogenannten Origamis, angewandt werden k√∂nnen.

# 1 Einf√ºhrung

## 1.1 Origamis

Origamis sind mathematische Objekte die sich recht anschaulich definieren lassen:

**Definition**:

Ein Origami O ist, bis auf √Ñquivalenz, definiert durch eine geschlossene Fl√§che, die gegeben ist durch Verkleben von endlich vielen Einheitsquadraten nach den sogenannten 

Origami-Regeln:

‚Ä¢ jede obere Kante wird mit einer eindeutig bestimmten unteren Kante und

‚Ä¢ jede rechte Kante wird mit einer eindeutig bestimmten linken Kante verklebt


Ein einfaches Beispiel ist der Torus (Donut), der durch Verkleben gegen√ºberliegende Seiten eines Einheitsquadrates entsteht.

Diese Definition erlaubt es Origamis auch rein kombinatorisch durch zwei Permutationen sigma_ x und sigma_y in S_d, zu fassen, wobei

‚Ä¢ sigma_x die horizontale und

‚Ä¢ sigma_y die vertikale 

Verklebestruktur beschreibt.


Obwohl damit Origamis kombinatorisch einfach zu fassende mathematische Objekte sind, tragen sie tiefliegende mathematische Strukturen und bilden somit einen Zugang f√ºr Methoden des maschinellen Lernens zur h√∂heren Mathematik.

Diese und weitere Informationen zu Origamis sind nachzulesen z.B. in:

F. Herrlich und G. Schmith√ºsen, Dessin d‚ÄôEnfants and Origami curves, A.
Papadopoulos (ed.) Handbook of Teichm√ºller theory, Vol. II, chapter 18.
European Mathematical Society (2009)

## 1.2 K√ºnstliche Neuronale Netze und Deep Learning

K√ºnstliche Neuronale Netze (KNN) sind EDV-Systeme die aus verbundenen Schichten k√ºnstlicher Neuronen zusammengesetzt sind.

Die Architektur orientiert sich hierbei an biologischen Vorlagen:

Einer Eingabeschicht werden die zu verarbeitenden Daten √ºbergeben, um dann gewichtet und durch eine Schwellenfunktion geregelt √ºber Zwischenschichten (Hidden Layer) verarbeitet zu werden und an einer Ausgabeschicht ein Ergebnis zu liefern.

Tiefe Neuronale Netze (TNN) weisen eine vergleichsweise gro√üe Anzahl von sogenannten Hidden Layers zwischen Eingabe- und Ausgabeschicht auf.

### 1.2.1 Clusteranalyse

Unter dem Begriff Clusteranalyse werden maschinelle Verfahren zur Gruppierung und Strukturierung von Objekten (Daten) nach gewissen Merkmalen der √Ñhnlichkeit oder N√§he in einem Eigenschaftsraum zusammengefasst.

Im Gegensatz zu Klassifizierungsverfahren werden hier keine gelabelten Trainingsdaten zum Erlernen eines Zuordnungsmodells ben√∂tigt.

Man unterscheidet im Wesentlichen drei Kategorien:

    ‚Ä¢     Partitions-Clustering
    
    ‚Ä¢     Dichtebasiertes Clustering
    
    ‚Ä¢     Hierarchisches Clustering


Im Folgenden wird aus jeder dieser Kategorien jeweils ein Clusteranalyse Algorithmus vorgestellt:

#### **K-Means Verfahren**:

K-Means ist ein Partitions-Clustering Verfahren.

Algorithmus:

    1. Manuelles Festlegen der Clusteranzahl und zuf√§lliges Festlegen der anf√§nglichen Clusterzentren
    
    2. Ermitteln der (quadrierten euklidischen) Abst√§nde der Datenpunkte zu den Clusterzentren und anschlie√üende Zuordnung zum n√§chstgelegenen Zentrum
    
    3. Neuberechnung der Clusterzentren durch Mittelwertbildung aller Abst√§nde zwischen Datenpunkten eine Clusters
    
    4. Wiederholen dieser Schritte f√ºr eine festgelegte Anzahl von Iterationen oder bis sich die Gruppenzentren zwischen den Iterationen nicht mehr wesentlich √§ndern. 

Vorteile:

    ‚Ä¢ Algorithmus mit linearer Komplexit√§t O(n)

Nachteile:

    ‚Ä¢ Manuelle Auswahl der Anzahl der Cluster
    
    ‚Ä¢ Zuf√§llige Initiierung der Clusterzentren liefert bei verschiedenen Durchl√§ufen u.U. unterschiedliche, also nicht wiederholbare Ergebnisse

#### **Dichtebasiertes r√§umliches Clustering von Anwendungen mit Rauschen (DBSCAN)**

DBSCAN ist ein dichtebasierter Cluster-Algorithmus

Algorithmus:

    1. W√§hle einen beliebigen (nicht als ‚Äúabgearbeitet‚Äù markierten Punkt als) Start Datenpunkt eines neuen Clusters und kennzeichne ihn als Kandidaten.
    
    2. Kennzeichne den Kandidaten als aktuellen Punkt, falls eine Mindestanzahl von Datenpunkten (Nachbarschafts Punkte) in einer vorgegebenen ùú∫-Umgebung um ihn liegen (Mindestdichte) und markiere ihn als abgearbeitet.
       Ansonsten kennzeichne den Kandidaten als Rauschen, markiere ihn als abgearbeitet und w√§hle einen neuen (nicht als ‚Äúabgearbeitet‚Äù markierte) Datenpunkt als Kandidaten (beliebig falls Kandidat Start Datenpunkt war, ansonsten aus der Œµ-Umgebung des aktuellen Punktes).

    3. Ordne alle Punkte die innerhalb der Œµ-Umgebung des aktuellen Punktes liegen dem aktuellen Cluster zu.
    
    4. W√§hle einen nicht als ‚Äúabgearbeitet‚Äù markierten Punkt aus der Œµ-Umgebung des aktuellen Punktes als neuen Kandidaten.
    
    5. Wiederhole Schritte 2, 3 und 4 bis keine weiteren Punkte dem Cluster hinzugef√ºgt werden, d.h. alle Punkte des Clusters als abgearbeitet markiert wurden.
    
    6. Wiederhole die Schritte 1 bis 5, bis alle Datenpunkte als abgearbeitet markiert wurden

Vorteile:

    ‚Ä¢ Keine manuelle Vorgabe der Clusteranzahl
    
    ‚Ä¢ Identifiziert Ausrei√üer als Rauschen
    
    ‚Ä¢ Findet zuverl√§ssig beliebig gro√üe und beliebig geformte Cluster

Nachteile:

    ‚Ä¢ Funktioniert schlecht bei variierender Clusterdichte (Abstandsschwelle Œµ und minPoints)
    
    
#### **Agglomeratives hierarchisches Clustering**

Hierarchische Clustering-Algorithmen lassen sich in zwei Kategorien einteilen:
Bottom Up und Top Down.

Bottom-up-Algorithmen fassen zu Beginn jeden Datenpunkt als einen einzelnen Cluster auf und f√ºhren diese dann schrittweise zusammen (agglomerieren sie), bis schlie√ülich alle Datenpunkte in einem einzigen Cluster enthalten sind.

Sie werden meist als Baumdiagramm (oder Dendrogramm) dargestellt.


Algorithmus:

    1. Fasse jeden Datenpunkt als einzelnen Cluster auf.
       W√§hle eine Abstandsmetrik, die den Abstand zwischen zwei Clustern misst.
       (Meist durchschnittlichen Abstand zwischen Datenpunkten im ersten Cluster und Datenpunkten im zweiten Cluster)
       
    2. Kombiniere je zwei Cluster, die, nach einer festgelegten Abstandsfunktion (etwa durchschnittlichen Entfernung zwischen Datenpunkten im ersten Cluster und Datenpunkten im zweiten Cluster), den geringsten Abstand untereinander haben.
    
    3. Wiederhole diesen Schritt bis alle Datenpunkte in einem Cluster zusammengefasst sind.

Vorteile:

    ‚Ä¢ Keine manuelle Vorgabe der Clusteranzahl
    
    ‚Ä¢ Liefert in einem Durchlauf Clusteringergebnisse mit unterschiedlichen Clusteranzahlen
    
    ‚Ä¢ Reagiert nicht bei √Ñnderung der Wahl der Entfernungsmetrik
    
    ‚Ä¢ Erkennt hierarchische Strukturen in den Daten

Nachteile:

    ‚Ä¢ Geringe Effizienz (zeitliche Komplexit√§t von O (n¬≥))
    
#### **Autoencoder**

Ein wesentliches Problem bei der Anwendung von Clusteringmethoden ist die Dimension des Eigenschaftraums (Feature Space), in dem die zu verarbeitenden Daten strukturiert werden. Bei der Bildverarbeitung zum Beispiel entspricht diese Dimension der Pixelanzahl.
Je h√∂her diese Dimension ist, desto schlechter arbeitet der Clusteringalgorithmus.

Um dieses Problem zu umgehen k√∂nnen sogenannte Autoencoder verwendet werden.

Das sind zweistufige Algorithmen, die im ersten Schritt, dem Encoding, Eingabedaten auf Merkmale mit niedrigerer Dimension komprimieren, um sie im zweiten Schritt, dem Decoding, aus den komprimierten Daten wieder zu rekonstruieren. 

Die zugeh√∂rige (meist spiegelsymmetrische) Implementierung als Neuronales Netz wird trainiert in dem die rekonstruierten Daten mit den zugeh√∂rigen Eingaben verglichen werden und das KNN anschlie√üend entsprechend angepasst wird.

Die Clusteringalgorithmen werden dann auf die niedrig dimensionalen encodierten Daten angewendet.

### 1.2.2 One Shot Learning

Ein wesentliches Problem bei Klassifizierungsverfahren ist, dass sie viele gelabelte Trainingsdaten (Daten, die mit ihrer Klassifizierungszuordnung annotiert sind) erfordern. In vielen Anwendungen ist es manchmal nicht m√∂glich, so viele Daten zu sammeln. One Shot Learning soll dieses Problem l√∂sen.

Im Folgenden soll ein Verfahren dazu vorgestellt werden:

One Shot Learning mit Siamesischen Netzwerken

Ein Siamesisches Neuronales Netzwerk besteht aus zwei, in Architektur und Gewichten identischen Netzwerken, die parallel unabh√§ngige Eingaben verarbeiten und anhand eines erlernten Modells einen √Ñhnlichkeitswert etwa zwischen 0 und 1 
ausgeben, wobei die Eins im Fall identischer Eingaben geliefert wird / liefern, der die Wahrscheinlichkeit angibt, dass beiden Eingaben identisch sind.

Ein solches Netzwerk lernt also nicht eine Eingabe direkt einer der Ausgabeklassen zuzuordnen. Vielmehr lernt es eine √Ñhnlichkeitsfunktion, die zwei Eingaben vergleicht und ausdr√ºckt, wie √§hnlich sie sind.

Die verwendete Netzwerkarchitektur und die Hyperparameter folgen hierbei der Methodik, die im Paper 

**Siamese Neural Networks for One-shot Image Recognition**

von Gregory Koch, Richard Zemel und Ruslan Salakhutdinov beschrieben werden.

Insbesondere werden dabei Convolutional Neuronal Networks (CNN) verwendet, die lokalisierte Merkmale aus Eingangsbildern extrahieren und diese Bildfelder mittels Filtern auffalten.

# 1.3 Darstellung von Origamis als Pixelmuster in Python

Im Folgenden sollen alle Algorithmen vorgestellt werden die zur Erzeugung und Darstellung aller Origamis einer bestimmten L√§nge in Python verwendet werden.

Dabei wird in folgender Reihenfolge vorgegangen:

    1. Erzeugen aller Zykeltypen der L√§nge l /in /N (horizontale Verklebung)
       √úbersetze in Standarddarstellung
       
    2. Erzeuge alle Permutationen der L√§nge l /in /N (vertikale Verklebung)
       √úbersetze in Zykeldarstellung
       
    3. Erzeuge alle Origamis der L√§nge l /in /N
    
    4. Sortiere alle nicht zusammenh√§ngenden Origamis aus
    
    5. Erzeuge zugeh√∂rige Pixelmuster

### 1.3.1 Erzeuge alle Origamis der L√§nge l /in /N 

#### **Erzeugen aller Zykeltypen der L√§nge l /in /N**

Die Verklebestruktur eines Origamis ist invariant unter Umnummerierung der Einheitsquadrate.
Damit ist die gesamte Information √ºber die Verklebung in eine Richtung bereits durch die Zykelstruktur festgelegt.

Die Bestimmung der Zykeltypen der L√§nge l /in /N ist dabei mathematisch identisch zu der Bestimmung der Summandenzerlegung von l.
      
Erzeuge zun√§chst die Liste L der Zykell√§ngen einer Permutation der L√§nge l. Aus ihr werden in folgender Weise alle entsprechenden Zykeltypen erzeugt:

    ‚Ä¢ Jeder Zykeltyp wird erzeugt als Liste von Listen, wobei jede Unterliste (Zykelliste) einem Zykel entspricht und deren L√§ngen durch den zugeh√∂rigen Eintrag in L bestimmt ist.
    
    ‚Ä¢ Die Zykellisten sind nach der L√§nge geordnet, von k√ºrzeste zu l√§ngste.
    
    ‚Ä¢ Die Elemente der Zykellisten sind genau die Zahlen von 1 bis l, die aufsteigend, beginnend mit der Eins und √ºber alle Listen hinweg fortlaufend eingesetzt werden. 

Diese Vorgehensweise sichert eine eindeutige und konsistente Darstellung der Zykeltypen.

#### **Erzeugen aller Permutation der L√§nge l /in /N**

Eine Liste aller Permutationen wird in Python als Liste von Tupeln durch die Funktion

	itertools.permutations()

erzeugt.

#### **Erzeugen aller Origamis der L√§nge l /in /N**

Kombiniere je einen

    ‚Ä¢ Zykeltyp 	in Zykel- und Standarddarstellung   (horizontale Verklebung)  mit einer
    
    ‚Ä¢ Permutation 	in Zykel- und Standarddarstellung   (vertikale Verklebung)

#### **Aussortieren aller nicht zusammenh√§ngender Origamis**

Abgeschlossene Verklebungen von Einheitsquadraten nach Vorgabe eines Zykels werden im Folgenden als Block bezeichnet.

Um zu √ºberpr√ºfen, ob ein Origami zusammenh√§ngend ist, gen√ºgt es festzustellen, ob etwa ein Teil der horizontalen Bl√∂cke vertikal (quadrat weise) nur mit sich selbst verklebt sind.

Es m√ºssen dabei nicht alle (horizontalen) Blockkombinationen √ºberpr√ºft werden, denn falls eine Blockkombination bzgl. vertikaler Verklebung nicht abgeschlossen ist, so ist auch dessen Komplement nicht abgeschlossen.

### 1.3.2 Erzeugen von Pixelmustern f√ºr alle Origamis der L√§nge l /in /N

In diesem Abschnitt sollen zwei verschiedene Pixeldarstellungen f√ºr Origamis zur √úbergabe an Neuronale Netze vorgestellt werden.

Diese orientieren sich an prominenten Datens√§tzen aus dem Bereich Computer Vision (Deep Learning Verfahren zur Bilderkennung).

Dar√ºber hinaus sind eine Vielzahl anderer Darstellungen denkbar.

Die Pixelmuster k√∂nnen auch augmentiert werden etwa durch weitere zahlenm√§√üig/kombinatorisch darstellbare/kodierbare Eigenschaften.

Es ist auch m√∂glich einzelne Merkmale mehr oder weniger zu betonen, so dass sie bei der Verarbeitung durch Neuronale Netze unterschiedlich stark ber√ºcksichtigt werden.

#### **Pixeldarstellung in Anlehnung an den MNIST, Fashion MNIST Datensatz**

Der Fashion-MNIST Datensatz besteht aus gelabelten graustufen Artikelbildern des Versandh√§ndlers Zalando vom Format 28x28 (784 Pixel), die jeweils mit einer Beschriftung aus 10 Klassen versehen sind.
Die Daten setzten sich dabei zusammen aus 60 000 Trainings- und 10 000 Test Beispielen, wobei jede Klasse gleich h√§ufig auftritt.
Jedem Pixel ist ein einzelner Pixelwert zugeordnet, der die Graustufe als Wert zwischen 0 und 255 angibt, wobei h√∂here Zahlen dunkleren Pixeln entsprechen. 
Die Trainings- und Testdatens√§tze haben 785 Spalten, wobei die erste Spalte die Klassenbezeichnungen (siehe oben) enth√§lt. Der Rest der Spalten enth√§lt die Pixelwerte des zugeordneten Bildes.

Algorithmus zur Erzeugung des Pixelmusters:

    ‚Ä¢ Erzeuge eine Pixelmatrix vom Format (2*l)x(l+1)
    
    ‚Ä¢ Beginnend beim l-ten Pixel in der obersten Zeile und nach links fortfahrend, setze als Pixelwert den Wert des entsprechenden Eintrags der Standarddarstellung der horizontalen Verklebestruktur
    
    ‚Ä¢ Beginnend beim (l+1)-ten Pixel in der obersten Zeile und nach rechts fortfahrend, setze als Pixelwert den Wert des entsprechenden Eintrags der Standarddarstellung der vertikalen Verklebestruktur
    
    ‚Ä¢ Beginnend beim l-ten Pixel in der zweitobersten Zeile und nach links bzw. bei Zykelwechsel nach unten fortfahrend, setze als Pixelwert den Wert des entsprechenden Eintrags des aktuellen Zykels, beginnend mit dem Ersten, der Zykeldarstellung der horizontalen Verklebestruktur
   
    ‚Ä¢ Beginnend beim (l+1)-ten Pixel in der zweitobersten Zeile und nach rechts bzw. bei Zykelwechsel nach unten fortfahrend, setze als Pixelwert den Wert des entsprechenden Eintrags des aktuellen Zykels, beginnend mit dem Ersten, der Zykeldarstellung der vertikalen Verklebestruktur
 
#### **Pixeldarstellung in Anlehnung an den Omniglot Datensatz**

Der Omniglot-Datensatz besteht aus graustufen Bildern im Format 105x105 von handgeschriebenen Zeichen nach Vorlage von insgesamt 1623 Buchstaben aus 50 verschiedenen Alphabeten.
F√ºr jedes Zeichen gibt es nur 20 Beispiele die jeweils von einer anderen Person geschrieben wurden.
Jedem Pixel ist ein einzelner Pixelwert zugeordnet, der die Graustufe als Wert zwischen 0 und 255 angibt, wobei h√∂here Zahlen dunkleren Pixeln entsprechen.

Der Datensatz kann unter

	GitHub - brendenlake/omniglot: Omniglot data set for one-shot learning
heruntergeladen werden.


Erzeugung der Pixelmusters:

	M := {Menge aller Eintr√§ge i.d. bisher abgearbeiteten horizontalen Zykeln}
  
	N := {Menge aller Eintr√§ge i.d. bisher abgearbeiteten vertikalen Zykeln}

Vorgehensweise:

    ‚Ä¢ Ordne jedem horizontalen Zykeleintrag ein Pixelblock vom Format
	      2a x a
	    zu
      
    ‚Ä¢ Ordne jedem vertikalen Zykeleintrag ein Pixelblock vom Format
	      a x 2a
	    zu
      
    ‚Ä¢ Lasse einen Rand/Rahmen mit einer St√§rke von 2a Pixeln/K√§stchen
    
Algorithmus zur Erzeugung des Pixelmusters:

    Horizontaler Anfangsblock:
    
    ‚Ä¢ Beginne bei der Anfangskoordinate (53, 53)
    
    ‚Ä¢ Erzeuge einen horizontalen Block nach links nach Vorgabe des ersten horizontalen Zykels
    
    ‚Ä¢ Aktualisiere M
    
    ‚Ä¢ W√§hle den vertikalen Zykel, der den letzten Eintrag des aktuellen horizontalen Zykels enth√§lt als aktuellen vertikalen Zykel

    Vertikaler Ansatzblock:
    
    ‚Ä¢ W√§hle als Ansatzkoordinaten den letzten (a x a)-Pixelblock des letzten Eintrags des horiziontalen Anfangsblockss
    
    ‚Ä¢ Setze einen vertikalen Block nach Vorgabe des aktuellen vertikalen Zykels nach oben an, falls der Zahlwert des Ansatzeintrags gerade ist andernfalls nach unten
   
    ‚Ä¢ Aktualisiere N
   
    ‚Ä¢ √úberpr√ºfe jeden Eintrag des aktuellen vertikalen Zykels, beginnend mit dem letzten, ob dieser bereits in M liegt. Ist dies der Fall, √ºberpr√ºfe den n√§chsten Eintrag. Ist dies nicht der Fall (und der Eintrag ist horizontal nicht mit sich selbst verklebt), w√§hle diesen als Ansatzeintrag und denjenigen horizontalen Zykel der diesen Eintrag enth√§lt als aktuellen horizontalen Zykel 

    Horizontaler Ansatzblock:
    
    ‚Ä¢ W√§hle als Ansatzkoordinaten den letzten (a x a)-Pixelblock des Ansatzeintrags des aktuellen vertikalen Zykels
   
    ‚Ä¢ Setze einen horizontalen Block nach Vorgabe des aktuellen horizontalen Zykels nach links an, falls der Zahlwert des Ansatzeintrags gerade ist andernfalls nach rechts
    
    ‚Ä¢ Aktualisiere M
    
    ‚Ä¢ √úberpr√ºfe jeden Eintrag des aktuellen horizontalen Zykels, beginnend mit dem letzten, ob dieser bereits in N liegt. Ist dies der Fall, √ºberpr√ºfe den n√§chsten Eintrag. Ist dies nicht der Fall (und der Eintrag ist vertikal nicht mit sich selbst verklebt), w√§hle diesen als Ansatzeintrag und denjenigen vertikalen Zykel der diesen Eintrag enth√§lt als aktuellen vertikalen Zykel. 

    Wiederhole die letzten beiden Schritte, bis gilt
	    M = {1, 2, ‚Ä¶, l}

Wiederhole anschlie√üend obigen Algorithmus, wobei zun√§chst ein vertikaler Anfangsblock nach rechts erzeugt wird und die Fortsetzungsrichtungen in Abh√§ngigkeit vom Wert des Ansatzeintrags vertauscht sind.

## 2 Anwendung und Ergebnisse

## 2.1 Anwendung von Clusteringverfahren auf Origamis

### 2.1.1 K-Means, DBSCAN, Agglomerative Clustering, ohne Autoencoder

Ohne die Anwendung eines Autoencoders (zur Reduktion der Dimensionen des Eigenschaftsraum) liefern die Clusteringverfahren keine brauchbaren Ergebnisse.

### 2.1.2 K-Means, DBSCAN, Agglomerative Clustering, mit Autoencoder

Die auf die encodierten Daten angewendeten Clusteringalgorithmen liefern brauchbare Ergebnisse, wobei unter den verwendeten Autoencoder Architekturen der Deep Autoencoder (ohne Convolutional Layer) am Besten arbeitet. 

K-Means zeigt die Tendenz vornehmlich nach der horizontalen Verklebestruktur zu Clustern.

In jedem Fall ist eine Augmentierung und Ausprobieren weiterer Darstellungen der Daten sinnvoll.

Der Code f√ºr die Autoencoder wurde im Wesentlichen aus

https://blog.keras.io/building-autoencoders-in-keras.html
  
√ºbernommen und entsprechend angepasst.

## 2.2 Anwendung von One-Shot-Learning auf Origamis zum Auffinden √§hnlicher Origamis

Da das Siamese Network direkt auf der Liste der Pixeldarstellungen trainiert und es je Pixeldarstellung/Origami nur ein Beispiel gibt, ist die Gefahr f√ºr Overfitting recht hoch.

Grunds√§tzlich sind folgende Alternativen sinnvoll:

    ‚Ä¢ Erzeugen weiterer Beispiele f√ºr die Pixeldarstellung eines Origamis durch Variation der angesetzten horizontalen/vertikalen Bl√∂cke (z.B. Blockbreite-, dicke, leicht schr√§ge Bl√∂cke etc.) und des jeweiligen Ansatzblocks (pixelweises Verschieben)

    ‚Ä¢ Trainieren des Modells auf dem Omniglot Datensatz (zur Feature Extraction) und anschlie√üendes Anwenden auf die Liste der Pixeldarstellungen

Auch hier ist eine Augmentierung oder Erweiterung der Pixeldarstellung empfehlenswert.

Der Code f√ºr das Siamese Network wurde im Wesentlichen aus

https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks/blob/master/Siamese%20on%20Omniglot%20Dataset.ipynb

√ºbernommen und entsprechend angepasst.

